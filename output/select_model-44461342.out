
Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/2.1.1


Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/2.1.1

The following have been reloaded with a version change:
  1) cuda/10.0.130 => cuda/8.0.44

Start Time: Mon Jun 22 16:21:16 PDT 2020
Param path params_attn_pg.json
Model path models/train_1592858367/model/model_1000_1592858561.6742206
max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.
Finished constructing vocabulary of 50000 total words. Last word added: pathogens
cuda:0
example_generator completed reading all datafiles. No more data.
1000 example in 112 sec
/project/6025349/vincenth/.venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/project/6025349/vincenth/.venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/project/6025349/vincenth/.venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/project/6025349/vincenth/.venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/project/6025349/vincenth/.venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/project/6025349/vincenth/.venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0
max_combination: 2300
Decoder has finished reading dataset for single_pass.
Scores of python rouge:
{'rouge-1': {'f': 0.16993659808996758, 'p': 0.20590227735547462, 'r': 0.1562257502872168}, 'rouge-2': {'f': 0.11367208595401695, 'p': 0.14165141281291674, 'r': 0.10233576279642183}, 'rouge-l': {'f': 0.16527094981001647, 'p': 0.20047569820827052, 'r': 0.15178264215846562}}
Now starting ROUGE eval...
Writing final ROUGE results to models/train_1592858367/model/valid.decode_model_1000_1592858561.6742206/ROUGE_results.txt...
Param path params_attn_pg.json
Model path models/train_1592858367/model/model_2000_1592858745.0978785
max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.
Finished constructing vocabulary of 50000 total words. Last word added: pathogens
cuda:0
example_generator completed reading all datafiles. No more data.
1000 example in 166 sec
WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0
max_combination: 4200
Decoder has finished reading dataset for single_pass.
Scores of python rouge:
{'rouge-1': {'f': 0.26565689038405155, 'p': 0.29793476002078817, 'r': 0.2674840242080576}, 'rouge-2': {'f': 0.17538537207775626, 'p': 0.19796561690243372, 'r': 0.17351157169935655}, 'rouge-l': {'f': 0.25773563437951896, 'p': 0.2893435467220546, 'r': 0.25857247474385936}}
Now starting ROUGE eval...
Writing final ROUGE results to models/train_1592858367/model/valid.decode_model_2000_1592858745.0978785/ROUGE_results.txt...
Param path params_attn_pg.json
Model path models/train_1592858367/model/model_3000_1592858929.39499
max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.
Finished constructing vocabulary of 50000 total words. Last word added: pathogens
cuda:0
example_generator completed reading all datafiles. No more data.
1000 example in 137 sec
WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0
max_combination: 4100
Decoder has finished reading dataset for single_pass.
Scores of python rouge:
{'rouge-1': {'f': 0.32895603648731814, 'p': 0.376033165768642, 'r': 0.32627172333756255}, 'rouge-2': {'f': 0.20811658921759857, 'p': 0.2399594748101006, 'r': 0.20269024497239171}, 'rouge-l': {'f': 0.31600085217071716, 'p': 0.3621657716545833, 'r': 0.31206566926526036}}
Now starting ROUGE eval...
Writing final ROUGE results to models/train_1592858367/model/valid.decode_model_3000_1592858929.39499/ROUGE_results.txt...
Param path params_attn_pg.json
Model path models/train_1592858367/model/model_4000_1592859113.4276574
max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.
Finished constructing vocabulary of 50000 total words. Last word added: pathogens
cuda:0
example_generator completed reading all datafiles. No more data.
1000 example in 155 sec
WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0
max_combination: 4700
Decoder has finished reading dataset for single_pass.
Scores of python rouge:
{'rouge-1': {'f': 0.3083972287337459, 'p': 0.3283225028711169, 'r': 0.3324548185742948}, 'rouge-2': {'f': 0.19247999154514894, 'p': 0.20626014113979008, 'r': 0.20331164259225948}, 'rouge-l': {'f': 0.2955780770475496, 'p': 0.3150274175676806, 'r': 0.3172669291678031}}
Now starting ROUGE eval...
Writing final ROUGE results to models/train_1592858367/model/valid.decode_model_4000_1592859113.4276574/ROUGE_results.txt...
Param path params_attn_pg.json
Model path models/train_1592858367/model/model_5000_1592859298.0744436
max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.
Finished constructing vocabulary of 50000 total words. Last word added: pathogens
cuda:0
example_generator completed reading all datafiles. No more data.
1000 example in 133 sec
WARNING:tensorflow:Bucket input queue is empty when calling next_batch. Bucket queue size: 0, Input queue size: 0
Traceback (most recent call last):
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.6.3/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.6.3/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/project/6025349/vincenth/PRSummarizer/prsum/prsum.py", line 567, in <module>
    fire.Fire(PRSum)
  File "/project/6025349/vincenth/.venv/lib/python3.6/site-packages/fire/core.py", line 138, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File "/project/6025349/vincenth/.venv/lib/python3.6/site-packages/fire/core.py", line 468, in _Fire
    target=component.__name__)
  File "/project/6025349/vincenth/.venv/lib/python3.6/site-packages/fire/core.py", line 672, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "/project/6025349/vincenth/PRSummarizer/prsum/prsum.py", line 475, in select_model
    result_dict = decode_processor.decode()
  File "/project/6025349/vincenth/PRSummarizer/prsum/decode.py", line 110, in decode
    best_summary = self.beam_search(batch)
  File "/project/6025349/vincenth/PRSummarizer/prsum/decode.py", line 202, in beam_search
    enc_features, enc_padding_mask, extend_vocab_zeros, enc_batch_extended, coverage_t)
  File "/project/6025349/vincenth/.venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/project/6025349/vincenth/PRSummarizer/prsum/pointer_model.py", line 160, in forward
    e_t = self.v(torch.tanh( enc_features + self.W_s(s_t_hat) )).squeeze(-1)
RuntimeError: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 0
max_combination: 4554
Decoder has finished reading dataset for single_pass.
Scores of python rouge:
{'rouge-1': {'f': 0.31130300217370604, 'p': 0.35580058965889416, 'r': 0.3111479395144283}, 'rouge-2': {'f': 0.18477754842378333, 'p': 0.20889343878301483, 'r': 0.18295128771473726}, 'rouge-l': {'f': 0.29770430997445474, 'p': 0.3403957978536405, 'r': 0.2963648140563444}}
Now starting ROUGE eval...
Writing final ROUGE results to models/train_1592858367/model/valid.decode_model_5000_1592859298.0744436/ROUGE_results.txt...
Param path params_attn_pg.json
Model path models/train_1592858367/model/model_6000_1592859483.3742366
max_size of vocab was specified as 50000; we now have 50000 words. Stopping reading.
Finished constructing vocabulary of 50000 total words. Last word added: pathogens
cuda:0
Start Time: Mon Jun 22 16:21:16 PDT 2020
End Time: Mon Jun 22 16:37:44 PDT 2020
